{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bvharshith/pws/blob/main/HDPD1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9wW7x4oZI-9"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# Path to the directory containing images\n",
        "directory_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in files:\n",
        "    # Check if the file is an image (you may want to refine this check based on your file extensions)\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        # Load the image\n",
        "        image_path = os.path.join(directory_path, file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Save the grayscale image\n",
        "        grayscale_image_path = os.path.join(directory_path, f\"grayscale_{file}\")\n",
        "        cv2.imwrite(grayscale_image_path, gray_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "Dyp47BF8ZrVM",
        "outputId": "b08e8c63-cbb9-4517-9f99-c1b06922efa3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'gray_image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3934554c3526>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example resizing images to 256x256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gray_image' is not defined"
          ]
        }
      ],
      "source": [
        "# Example resizing images to 256x256\n",
        "resized_image = cv2.resize(gray_image, (256, 256))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "By2P3Ov5Z-yk",
        "outputId": "133a2bc1-aee6-4858-c68b-2ed6dfbae27e"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-30387528388d>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Split dataset into training and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2236\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2237\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2238\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np  # Import NumPy for array operations\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to the directory containing images\n",
        "directory_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# List all files in the directory\n",
        "files = os.listdir(directory_path)\n",
        "\n",
        "# Lists to store images and labels (if applicable)\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in files:\n",
        "    # Check if the file is an image (you may want to refine this check based on your file extensions)\n",
        "    if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
        "        # Load the image\n",
        "        image_path = os.path.join(directory_path, file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Perform further processing steps\n",
        "\n",
        "        # Resize image\n",
        "        resized_image = cv2.resize(gray_image, (256, 256))\n",
        "\n",
        "        # Normalize pixel values\n",
        "        normalized_image = gray_image / 255.0\n",
        "\n",
        "        # Perform data augmentation (example: rotate by 90 degrees)\n",
        "        rotated_image = cv2.rotate(gray_image, cv2.ROTATE_90_CLOCKWISE)\n",
        "\n",
        "        # Append processed image to list\n",
        "        images.append(resized_image)  # Change this to the appropriate processed image\n",
        "        # If you have labels, append them as well\n",
        "        # labels.append(label)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "# labels = np.array(labels)\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Zy2fHMPZaPIa",
        "outputId": "49532c6e-15e2-4840-ac8e-2a087502f688"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "test_size=0.0 should be either positive and smaller than the number of samples 0 or a float in the (0, 1) range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9292bdd2e905>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split dataset into training and test sets (using all data for training)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m     n_train, n_test = _validate_shuffle_split(\n\u001b[0m\u001b[1;32m   2563\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2179\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m     ):\n\u001b[0;32m-> 2181\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2182\u001b[0m             \u001b[0;34m\"test_size={0} should be either positive and smaller\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m             \u001b[0;34m\" than the number of samples {1} or a float in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: test_size=0.0 should be either positive and smaller than the number of samples 0 or a float in the (0, 1) range"
          ]
        }
      ],
      "source": [
        "# Split dataset into training and test sets (using all data for training)\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.0, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8r1b8SIa0mE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if folder_name not in label_mapping:\n",
        "                label_mapping[folder_name] = current_label\n",
        "                current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load image and convert to grayscale\n",
        "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        X.append(img)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Rest of the code remains the same\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtDp5CrzbKt4",
        "outputId": "dd23fa7f-5f76-4000-d6fa-4d993700aff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your dataset directory\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if folder_name not in label_mapping:\n",
        "                label_mapping[folder_name] = current_label\n",
        "                current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load image and convert to grayscale\n",
        "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        X.append(img)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Rest of the code remains the same\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhG2CbtpbYK_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Define the path to your dataset directory\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if folder_name not in label_mapping:\n",
        "                label_mapping[folder_name] = current_label\n",
        "                current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load image and convert to grayscale\n",
        "                    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        X.append(img)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Rest of the code remains the same\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLZNsl8bbuBT"
      },
      "outputs": [],
      "source": [
        "from skimage.color import rgb2gray\n",
        "\n",
        "# 2. Feature Extraction with Grayscale Conversion\n",
        "def extract_features(X):\n",
        "    features = []\n",
        "    for img in X:\n",
        "        # Convert image to grayscale\n",
        "        gray_img = rgb2gray(img)\n",
        "\n",
        "        # Example: Using Histogram of Oriented Gradients (HOG) as features\n",
        "        hog_features = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                           cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
        "        features.append(hog_features)\n",
        "    return np.array(features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpejm3Bfbv3S"
      },
      "outputs": [],
      "source": [
        "from skimage.color import rgb2gray\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "uaqOXixeb3jL",
        "outputId": "5939d563-a489-4783-abc8-7dfa7ba3f111"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "the input array must have size 3 along `channel_axis`, got (420, 561)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d17b235d600b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d17b235d600b>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# 2. Feature Extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# 3. Splitting the Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-0f99c1ecd240>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Convert image to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mgray_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Example: Using Histogram of Oriented Gradients (HOG) as features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mfixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;31m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2gray\u001b[0;34m(rgb, channel_axis)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mimg_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \"\"\"\n\u001b[0;32m--> 875\u001b[0;31m     \u001b[0mrgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0mcoeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.2125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7154\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0721\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgb\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mcoeffs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr, force_copy, channel_axis)\u001b[0m\n\u001b[1;32m    138\u001b[0m         msg = (f'the input array must have size 3 along `channel_axis`, '\n\u001b[1;32m    139\u001b[0m                f'got {arr.shape}')\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mfloat_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_supported_float_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: the input array must have size 3 along `channel_axis`, got (420, 561)"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 3. Splitting the Dataset\n",
        "def split_dataset(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# 4. Model Training\n",
        "def train_model(X_train, y_train):\n",
        "    # Example: Train an SVM classifier\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    svm_classifier = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "    svm_classifier.fit(X_train_scaled, y_train)\n",
        "    return svm_classifier\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # 2. Feature Extraction\n",
        "    X_features = extract_features(X)\n",
        "\n",
        "    # 3. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_features, y)\n",
        "\n",
        "    # 4. Model Training\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # 5. Model Evaluation\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TKd_7-OcCDF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if folder_name not in label_mapping:\n",
        "                label_mapping[folder_name] = current_label\n",
        "                current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load image\n",
        "                    img = cv2.imread(file_path)\n",
        "                    if img is not None:\n",
        "                        # Resize image if needed\n",
        "                        img = cv2.resize(img, (224, 224))  # Adjust size as needed\n",
        "                        X.append(img)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Rest of the code remains the same\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "q5_4MNlmcOmD",
        "outputId": "53d18fa7-b8e1-4f06-a04f-3a9ee4b248d8"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'hog' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d15af7da2ddb>\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-d15af7da2ddb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# 2. Feature Extraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mX_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# 3. Splitting the Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-d15af7da2ddb>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Example: Using Histogram of Oriented Gradients (HOG) as features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         hog_features = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n\u001b[0m\u001b[1;32m     15\u001b[0m                            cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n\u001b[1;32m     16\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhog_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'hog' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 2. Feature Extraction (Example using HOG)\n",
        "def extract_features(X):\n",
        "    features = []\n",
        "    for img in X:\n",
        "        # Convert image to grayscale\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Example: Using Histogram of Oriented Gradients (HOG) as features\n",
        "        hog_features = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                           cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
        "        features.append(hog_features)\n",
        "    return np.array(features)\n",
        "\n",
        "# 3. Splitting the Dataset\n",
        "def split_dataset(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# 4. Model Training\n",
        "def train_model(X_train, y_train):\n",
        "    # Example: Train an SVM classifier\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    svm_classifier = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "    svm_classifier.fit(X_train_scaled, y_train)\n",
        "    return svm_classifier\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # 2. Feature Extraction\n",
        "    X_features = extract_features(X)\n",
        "\n",
        "    # 3. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_features, y)\n",
        "\n",
        "    # 4. Model Training\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # 5. Model Evaluation\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFgtHZJccYlr",
        "outputId": "06cef7ae-f30c-4bf8-8ca6-459f3769ae8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.feature import hog  # Importing the hog function\n",
        "\n",
        "# Define the path to your dataset directory\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            if folder_name not in label_mapping:\n",
        "                label_mapping[folder_name] = current_label\n",
        "                current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load image\n",
        "                    img = cv2.imread(file_path)\n",
        "                    if img is not None:\n",
        "                        # Resize image if needed\n",
        "                        img = cv2.resize(img, (224, 224))  # Adjust size as needed\n",
        "                        X.append(img)\n",
        "                        y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 2. Feature Extraction with Grayscale Conversion\n",
        "def extract_features(X):\n",
        "    features = []\n",
        "    for img in X:\n",
        "        # Convert image to grayscale\n",
        "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Extract HOG features\n",
        "        hog_features = hog(gray_img, orientations=9, pixels_per_cell=(8, 8),\n",
        "                           cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n",
        "        features.append(hog_features)\n",
        "    return np.array(features)\n",
        "\n",
        "# 3. Splitting the Dataset\n",
        "def split_dataset(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# 4. Model Training\n",
        "def train_model(X_train, y_train):\n",
        "    # Train an SVM classifier\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    svm_classifier = SVC(kernel='rbf', C=10, gamma='scale')\n",
        "    svm_classifier.fit(X_train_scaled, y_train)\n",
        "    return svm_classifier\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # 2. Feature Extraction\n",
        "    X_features = extract_features(X)\n",
        "\n",
        "    # 3. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_features, y)\n",
        "\n",
        "    # 4. Model Training\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # 5. Model Evaluation\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "ENGrZWE8cuEM",
        "outputId": "baac28cc-91ed-48a2-fc2c-2af650f35b9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.6\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABENklEQVR4nO3deVyU5f7/8feAMqgILiCohySXXBLFQA1NceGES5SWG2qYW53MJTmd0FLR00lt0ci0TFM5i1uWlqWZSnta5oKdOmqpuZXiDogJyty/P/o530YWoYTxstfz8ZhH3tdc131/7pFu31xzzzU2y7IsAQAAAAbycHcBAAAAwG9FmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBVCmbDabJk+eXOJxBw4ckM1mU0pKyjWvCShIhw4d1KFDB3eXAeAqCLPAH1BKSopsNptsNps+++yzfM9blqXg4GDZbDbdddddbqjw2li7dq1sNptq1aolh8Ph7nKMk5mZqSlTpqh58+by8fFRhQoV1LRpUyUmJuqnn35yd3kAIEkq5+4CALiPt7e3lixZojvuuMOl/eOPP9aRI0dkt9vdVNm1sXjxYoWEhOjAgQP64IMPFB0d7e6SjLF//35FR0fr0KFD6t27tx588EF5eXnp66+/1oIFC7Rq1Sp999137i6zVK1fv97dJQAoBmZmgT+wbt26acWKFbp06ZJL+5IlSxQeHq6goCA3Vfb7ZWdn6+2331ZCQoJatGihxYsXu7ukQmVnZ7u7BBeXLl3Svffeq/T0dH300UdaunSpHnnkEQ0fPlwvvfSS9u/fr969e7u7zFJz/vx5SZKXl5e8vLzcXA2AqyHMAn9gcXFxOnXqlDZs2OBsy83N1RtvvKH+/fsXOCY7O1t//etfFRwcLLvdroYNG+r555+XZVku/XJycjR27FgFBASocuXKuvvuu3XkyJEC9/njjz9qyJAhCgwMlN1u16233qqFCxf+rnNbtWqVfv75Z/Xu3Vv9+vXTypUrdeHChXz9Lly4oMmTJ+uWW26Rt7e3atasqXvvvVf79u1z9nE4HHrxxRcVGhoqb29vBQQEqEuXLtq6daukou/nvfIe4cmTJ8tms+l///uf+vfvr6pVqzpnxr/++ms98MADqlu3rry9vRUUFKQhQ4bo1KlTBb5mQ4cOVa1atWS323XzzTfr4YcfVm5urvbv3y+bzaYXXngh37hNmzbJZrNp6dKlhb52b775pnbu3Kknn3wy36y9JPn6+urpp592aVuxYoXCw8NVoUIF+fv7a+DAgfrxxx9d+jzwwAPy8fHRoUOHdNddd8nHx0e1a9fWnDlzJEn//e9/1alTJ1WqVEl16tTRkiVLXMZfvj3mk08+0UMPPaTq1avL19dX8fHxOnPmjEvft99+W927d3e+PvXq1dNTTz2lvLw8l34dOnRQ06ZNtW3bNrVv314VK1bUE0884XzuyntmX3rpJd16662qWLGiqlatqoiIiHx17tixQ127dpWvr698fHzUuXNnffHFFwWey+eff66EhAQFBASoUqVK6tmzp06cOFHQXwuAQhBmgT+wkJAQRUZGugSb9957TxkZGerXr1++/pZl6e6779YLL7ygLl26aObMmWrYsKH+9re/KSEhwaXvsGHDlJycrDvvvFPTp09X+fLl1b1793z7TE9P1+23366NGzdq5MiRevHFF1W/fn0NHTpUycnJv/ncFi9erI4dOyooKEj9+vVTVlaW3nnnHZc+eXl5uuuuuzRlyhSFh4drxowZGjNmjDIyMvTNN984+w0dOlSPPvqogoOD9cwzz2jcuHHy9vbOF1BKonfv3jp//rymTp2q4cOHS5I2bNig/fv3a/DgwXrppZfUr18/LVu2TN26dXP5ZeGnn35Sq1attGzZMvXt21ezZs3S/fffr48//ljnz59X3bp11bZt2wJnoxcvXqzKlSvrnnvuKbS21atXS5Luv//+Yp1LSkqK+vTpI09PT02bNk3Dhw/XypUrdccdd+js2bMuffPy8tS1a1cFBwfr2WefVUhIiEaOHKmUlBR16dJFEREReuaZZ1S5cmXFx8frhx9+yHe8kSNHateuXZo8ebLi4+O1ePFi9ejRw+U1SklJkY+PjxISEvTiiy8qPDxckyZN0rhx4/Lt79SpU+ratavCwsKUnJysjh07Fnie8+fP1+jRo9WkSRMlJydrypQpCgsL05dffuns8+2336pdu3bauXOnHn/8cU2cOFE//PCDOnTo4NLvslGjRmnnzp1KSkrSww8/rHfeeUcjR44s1usO4P+zAPzhLFq0yJJkffXVV9bs2bOtypUrW+fPn7csy7J69+5tdezY0bIsy6pTp47VvXt357i33nrLkmT94x//cNlfr169LJvNZu3du9eyLMtKS0uzJFkjRoxw6de/f39LkpWUlORsGzp0qFWzZk3r5MmTLn379etn+fn5Oev64YcfLEnWokWLrnp+6enpVrly5az58+c729q0aWPdc889Lv0WLlxoSbJmzpyZbx8Oh8OyLMv64IMPLEnW6NGjC+1TVG1Xnm9SUpIlyYqLi8vX9/K5/trSpUstSdYnn3zibIuPj7c8PDysr776qtCaXn31VUuStWvXLudzubm5lr+/vzVo0KB8436tRYsWlp+fX5F9fr3PGjVqWE2bNrV+/vlnZ/u7775rSbImTZrkbBs0aJAlyZo6daqz7cyZM1aFChUsm81mLVu2zNm+e/fufK/d5Z/b8PBwKzc319n+7LPPWpKst99+29lW0Gv50EMPWRUrVrQuXLjgbIuKirIkWXPnzs3XPyoqyoqKinJu33PPPdatt95a5OvRo0cPy8vLy9q3b5+z7aeffrIqV65stW/fPt+5REdHO//OLMuyxo4da3l6elpnz54t8jgA/g8zs8AfXJ8+ffTzzz/r3XffVVZWlt59991CbzFYu3atPD09NXr0aJf2v/71r7IsS++9956zn6R8/R599FGXbcuy9Oabbyo2NlaWZenkyZPOR0xMjDIyMrR9+/YSn9OyZcvk4eGh++67z9kWFxen9957z+Xt6DfffFP+/v4aNWpUvn3YbDZnH5vNpqSkpEL7/BZ/+ctf8rVVqFDB+ecLFy7o5MmTuv322yXJ+To4HA699dZbio2NVURERKE19enTR97e3i6zs++//75OnjypgQMHFllbZmamKleuXKzz2Lp1q44fP64RI0bI29vb2d69e3c1atRIa9asyTdm2LBhzj9XqVJFDRs2VKVKldSnTx9ne8OGDVWlShXt378/3/gHH3xQ5cuXd24//PDDKleunPPnTnJ9LbOysnTy5Em1a9dO58+f1+7du132Z7fbNXjw4Kuea5UqVXTkyBF99dVXBT6fl5en9evXq0ePHqpbt66zvWbNmurfv78+++wzZWZm5juXX/8ctWvXTnl5eTp48OBV6wHwC8Is8AcXEBCg6OhoLVmyRCtXrlReXp569epVYN+DBw+qVq1a+YJO48aNnc9f/q+Hh4fq1avn0q9hw4Yu2ydOnNDZs2c1b948BQQEuDwuh4vjx4+X+Jz+85//qFWrVjp16pT27t2rvXv3qkWLFsrNzdWKFSuc/fbt26eGDRuqXLnCF3bZt2+fatWqpWrVqpW4jqLcfPPN+dpOnz6tMWPGKDAwUBUqVFBAQICzX0ZGhqRfXrPMzEw1bdq0yP1XqVJFsbGxLvdzLl68WLVr11anTp2KHOvr66usrKxincflv/Mr/24lqVGjRvlC2eV7jn/Nz89Pf/rTn/L9cuDn55fvXlhJatCggcu2j4+PatasqQMHDjjbvv32W/Xs2VN+fn7y9fVVQECAM8Rffi0vq127drE+6JWYmCgfHx+1atVKDRo00COPPKLPP//c+fyJEyd0/vz5Al+Lxo0by+Fw6PDhwy7tN910k8t21apVJanA8wZQMJbmAqD+/ftr+PDhOnbsmLp27aoqVaqUyXEvr/06cOBADRo0qMA+zZo1K9E+v//+e+fM2ZWhR/ol0D344IMlrLRohc3QXvlho1/79czhZX369NGmTZv0t7/9TWFhYfLx8ZHD4VCXLl1+0zq58fHxWrFihTZt2qTQ0FCtXr1aI0aMkIdH0fMYjRo10o4dO3T48GEFBweX+LhF8fT0LFG7dcUHC4vj7NmzioqKkq+vr/7+97+rXr168vb21vbt25WYmJjvtSzo76IgjRs31p49e/Tuu+9q3bp1evPNN/Xyyy9r0qRJmjJlSonrlK7teQN/VIRZAOrZs6ceeughffHFF1q+fHmh/erUqaONGzcqKyvLZXb28tu2derUcf7X4XA4Zz4v27Nnj8v+Lq90kJeXd83WgF28eLHKly+vf//73/mCwmeffaZZs2bp0KFDuummm1SvXj19+eWXunjxosvb1r9Wr149vf/++zp9+nShs7OXZ9Ou/LBTSd4qPnPmjFJTUzVlyhRNmjTJ2f7999+79AsICJCvr6/LB9QK06VLFwUEBGjx4sVq3bq1zp8/X6wPdcXGxmrp0qX6z3/+o/HjxxfZ9/Lf+Z49e/LN+O7Zs8f5/LX0/fffu3xI69y5czp69Ki6desmSfroo4906tQprVy5Uu3bt3f2K+jDZCVVqVIl9e3bV3379lVubq7uvfdePf300xo/frwCAgJUsWLFfD/n0i//j3h4eFzzXw4AcJsBAP3yNu0rr7yiyZMnKzY2ttB+3bp1U15enmbPnu3S/sILL8hms6lr166S5PzvrFmzXPpduTqBp6en7rvvPr355psFhrPfskTR4sWL1a5dO/Xt21e9evVyefztb3+TJOfqDffdd59OnjyZ73yk/5sZu++++2RZVoEzb5f7+Pr6yt/fX5988onL8y+//HKx674cvK+ckbvyNfPw8FCPHj30zjvvOJcGK6gmSSpXrpzi4uL0+uuvKyUlRaGhocWa6e7Vq5dCQ0P19NNPa/Pmzfmez8rK0pNPPilJioiIUI0aNTR37lzl5OQ4+7z33nvatWtXgStY/F7z5s3TxYsXnduvvPKKLl265Py5K+i1zM3NLdHfR0GuXCLNy8tLTZo0kWVZunjxojw9PXXnnXfq7bffdrnlIT093fnlJL6+vr+rBgD5MTMLQJIKfZv/12JjY9WxY0c9+eSTOnDggJo3b67169fr7bff1qOPPuq8RzYsLExxcXF6+eWXlZGRoTZt2ig1NVV79+7Nt8/p06frww8/VOvWrTV8+HA1adJEp0+f1vbt27Vx40adPn262Ofw5Zdfau/evYUubVS7dm3ddtttWrx4sRITExUfH69//etfSkhI0JYtW9SuXTtlZ2dr48aNGjFihO655x517NhR999/v2bNmqXvv//e+Zb/p59+qo4dOzqPNWzYME2fPl3Dhg1TRESEPvnkkxJ9Q5avr6/at2+vZ599VhcvXlTt2rW1fv36AmcTp06dqvXr1ysqKkoPPvigGjdurKNHj2rFihX67LPPXG4TiY+P16xZs/Thhx/qmWeeKVYt5cuX18qVKxUdHa327durT58+atu2rcqXL69vv/1WS5YsUdWqVfX000+rfPnyeuaZZzR48GBFRUUpLi5O6enpevHFFxUSEqKxY8cW+zUortzcXHXu3Fl9+vTRnj179PLLL+uOO+7Q3XffLUlq06aNqlatqkGDBmn06NGy2Wz697///bvfur/zzjsVFBSktm3bKjAwULt27dLs2bPVvXt35zsV//jHP7RhwwbdcccdGjFihMqVK6dXX31VOTk5evbZZ3/3uQMogFvWUADgVr9emqsoVy7NZVmWlZWVZY0dO9aqVauWVb58eatBgwbWc88957K8kGVZ1s8//2yNHj3aql69ulWpUiUrNjbWOnz4cL7llizrl6W0HnnkESs4ONgqX768FRQUZHXu3NmaN2+es09xluYaNWqUJcllWaQrTZ482ZJk7dy507KsX5ZwevLJJ62bb77ZeexevXq57OPSpUvWc889ZzVq1Mjy8vKyAgICrK5du1rbtm1z9jl//rw1dOhQy8/Pz6pcubLVp08f6/jx44UuzXXixIl8tR05csTq2bOnVaVKFcvPz8/q3bu39dNPPxX4mh08eNCKj4+3AgICLLvdbtWtW9d65JFHrJycnHz7vfXWWy0PDw/ryJEjhb4uBTlz5ow1adIkKzQ01KpYsaLl7e1tNW3a1Bo/frx19OhRl77Lly+3WrRoYdntdqtatWrWgAED8h1v0KBBVqVKlfIdJyoqqsAlr678+bv8c/vxxx9bDz74oFW1alXLx8fHGjBggHXq1CmXsZ9//rl1++23WxUqVLBq1aplPf7449b7779vSbI+/PDDqx778nO/Xprr1Vdftdq3b29Vr17dstvtVr169ay//e1vVkZGhsu47du3WzExMZaPj49VsWJFq2PHjtamTZtc+hT2/+CHH36Yr0YARbNZFneZA8CNrEWLFqpWrZpSU1PdXcrvkpKSosGDB+urr74qcFkyAH9M3DMLADewrVu3Ki0tTfHx8e4uBQBKBffMAsAN6JtvvtG2bds0Y8YM1axZU3379nV3SQBQKpiZBYAb0BtvvKHBgwfr4sWLWrp0qcu3cwHAjcStYfaTTz5RbGysatWqJZvNprfeeuuqYz766CPddtttstvtql+/vlJSUkq9TgAwzeTJk+VwOLRr1y5FRUW5u5xr4oEHHpBlWdwvC8CFW8Nsdna2mjdvrjlz5hSr/w8//KDu3burY8eOSktL06OPPqphw4bp/fffL+VKAQAAcD26blYzsNlsWrVqlXr06FFon8TERK1Zs8ZlcfV+/frp7NmzWrduXRlUCQAAgOuJUR8A27x5c76vvIyJidGjjz5a6JicnByXb6VxOBw6ffq0qlevXuj3qQMAAMB9LMtSVlaWatWqJQ+Pom8kMCrMHjt2TIGBgS5tgYGByszM1M8//6wKFSrkGzNt2rQCv4YSAAAA17fDhw/rT3/6U5F9jAqzv8X48eOVkJDg3M7IyNBNN92kw4cPl9l3ZPv5lclhALhZRoa7KwCAG0NmZqaCg4OdXxVdFKPCbFBQkNLT013a0tPT5evrW+CsrCTZ7XbZ7fZ87b6+vmUWZgH8MXBJAYBrqzi3hBq1zmxkZGS+r2PcsGGDIiMj3VQRAAAA3MmtYfbcuXNKS0tTWlqapF+W3kpLS9OhQ4ck/XKLwK+/gvEvf/mL9u/fr8cff1y7d+/Wyy+/rNdff11jx451R/kAAABwM7eG2a1bt6pFixZq0aKFJCkhIUEtWrTQpEmTJElHjx51BltJuvnmm7VmzRpt2LBBzZs314wZM/Taa68pJibGLfUDAADAva6bdWbLSmZmpvz8/JSRkVFm98yyAhjwx/DHupoCQOkpSV4z6p5ZAAAA4NcIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsdweZufMmaOQkBB5e3urdevW2rJlS5H9k5OT1bBhQ1WoUEHBwcEaO3asLly4UEbVAgAA4Hri1jC7fPlyJSQkKCkpSdu3b1fz5s0VExOj48ePF9h/yZIlGjdunJKSkrRr1y4tWLBAy5cv1xNPPFHGlQMAAOB64NYwO3PmTA0fPlyDBw9WkyZNNHfuXFWsWFELFy4ssP+mTZvUtm1b9e/fXyEhIbrzzjsVFxd31dlcAAAA3JjcFmZzc3O1bds2RUdH/18xHh6Kjo7W5s2bCxzTpk0bbdu2zRle9+/fr7Vr16pbt26FHicnJ0eZmZkuDwAAANwYyrnrwCdPnlReXp4CAwNd2gMDA7V79+4Cx/Tv318nT57UHXfcIcuydOnSJf3lL38p8jaDadOmacqUKde0dgAAAFwf3P4BsJL46KOPNHXqVL388svavn27Vq5cqTVr1uipp54qdMz48eOVkZHhfBw+fLgMKwYAAEBpctvMrL+/vzw9PZWenu7Snp6erqCgoALHTJw4Uffff7+GDRsmSQoNDVV2drYefPBBPfnkk/LwyJ/N7Xa77Hb7tT8BAAAAuJ3bZma9vLwUHh6u1NRUZ5vD4VBqaqoiIyMLHHP+/Pl8gdXT01OSZFlW6RULAACA65LbZmYlKSEhQYMGDVJERIRatWql5ORkZWdna/DgwZKk+Ph41a5dW9OmTZMkxcbGaubMmWrRooVat26tvXv3auLEiYqNjXWGWgAAAPxxuDXM9u3bVydOnNCkSZN07NgxhYWFad26dc4PhR06dMhlJnbChAmy2WyaMGGCfvzxRwUEBCg2NlZPP/20u04BAAAAbmSz/mDvz2dmZsrPz08ZGRny9fUtk2PabGVyGABu9se6mgJA6SlJXjNqNQMAAADg1wizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwltvD7Jw5cxQSEiJvb2+1bt1aW7ZsKbL/2bNn9cgjj6hmzZqy2+265ZZbtHbt2jKqFgAAANeTcu48+PLly5WQkKC5c+eqdevWSk5OVkxMjPbs2aMaNWrk65+bm6s///nPqlGjht544w3Vrl1bBw8eVJUqVcq+eAAAALidzbIsy10Hb926tVq2bKnZs2dLkhwOh4KDgzVq1CiNGzcuX/+5c+fqueee0+7du1W+fPnfdMzMzEz5+fkpIyNDvr6+v6v+4rLZyuQwANzMfVdTALixlCSvue02g9zcXG3btk3R0dH/V4yHh6Kjo7V58+YCx6xevVqRkZF65JFHFBgYqKZNm2rq1KnKy8sr9Dg5OTnKzMx0eQAAAODG4LbbDE6ePKm8vDwFBga6tAcGBmr37t0Fjtm/f78++OADDRgwQGvXrtXevXs1YsQIXbx4UUlJSQWOmTZtmqZMmXLN6wcA/B/bFN6CAm50VtL1+faT2z8AVhIOh0M1atTQvHnzFB4err59++rJJ5/U3LlzCx0zfvx4ZWRkOB+HDx8uw4oBAABQmtw2M+vv7y9PT0+lp6e7tKenpysoKKjAMTVr1lT58uXl6enpbGvcuLGOHTum3NxceXl55Rtjt9tlt9uvbfEAAAC4LrhtZtbLy0vh4eFKTU11tjkcDqWmpioyMrLAMW3bttXevXvlcDicbd99951q1qxZYJAFAADAjc2ttxkkJCRo/vz5+uc//6ldu3bp4YcfVnZ2tgYPHixJio+P1/jx4539H374YZ0+fVpjxozRd999pzVr1mjq1Kl65JFH3HUKAAAAcCO3rjPbt29fnThxQpMmTdKxY8cUFhamdevWOT8UdujQIXl4/F/eDg4O1vvvv6+xY8eqWbNmql27tsaMGaPExER3nQIAAADcyK3rzLoD68wCKC1/rKupK1YzAG58ZbmagRHrzAIAAAC/F2EWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYKzfFGYvXbqkjRs36tVXX1VWVpYk6aefftK5c+euaXEAAABAUcqVdMDBgwfVpUsXHTp0SDk5Ofrzn/+sypUr65lnnlFOTo7mzp1bGnUCAAAA+ZR4ZnbMmDGKiIjQmTNnVKFCBWd7z549lZqaek2LAwAAAIpS4pnZTz/9VJs2bZKXl5dLe0hIiH788cdrVhgAAABwNSWemXU4HMrLy8vXfuTIEVWuXPmaFAUAAAAUR4nD7J133qnk5GTnts1m07lz55SUlKRu3bpdy9oAAACAIpX4NoMZM2YoJiZGTZo00YULF9S/f399//338vf319KlS0ujRgAAAKBAJQ6zf/rTn7Rz504tW7ZMX3/9tc6dO6ehQ4dqwIABLh8IAwAAAEpbicOsJJUrV04DBw681rUAAAAAJVLiMPuvf/2ryOfj4+N/czEAAABASZQ4zI4ZM8Zl++LFizp//ry8vLxUsWJFwiwAAADKTIlXMzhz5ozL49y5c9qzZ4/uuOMOPgAGAACAMlXiMFuQBg0aaPr06flmbQEAAIDSdE3CrPTLh8J++umna7U7AAAA4KpKfM/s6tWrXbYty9LRo0c1e/ZstW3b9poVBgAAAFxNicNsjx49XLZtNpsCAgLUqVMnzZgx41rVBQAAAFxVicOsw+EojToAAACAErtm98wCAAAAZa1YM7MJCQnF3uHMmTN/czEAAABASRQrzO7YsaNYO7PZbL+rGAAAAKAkihVmP/zww9KuAwAAACgx7pkFAACAsUq8moEkbd26Va+//roOHTqk3Nxcl+dWrlx5TQoDAAAArqbEM7PLli1TmzZttGvXLq1atUoXL17Ut99+qw8++EB+fn6lUSMAAABQoBKH2alTp+qFF17QO++8Iy8vL7344ovavXu3+vTpo5tuuqk0agQAAAAKVOIwu2/fPnXv3l2S5OXlpezsbNlsNo0dO1bz5s275gUCAAAAhSlxmK1ataqysrIkSbVr19Y333wjSTp79qzOnz9/basDAAAAilDsMHs5tLZv314bNmyQJPXu3VtjxozR8OHDFRcXp86dO5dOlQAAAEABir2aQbNmzdSyZUv16NFDvXv3liQ9+eSTKl++vDZt2qT77rtPEyZMKLVCAQAAgCvZLMuyitPx008/1aJFi/TGG2/I4XDovvvu07Bhw9SuXbvSrvGayszMlJ+fnzIyMuTr61smx+SL0YA/huJdTW9Mtilc6IAbnZVUdhe5kuS1Yt9m0K5dOy1cuFBHjx7VSy+9pAMHDigqKkq33HKLnnnmGR07dux3Fw4AAACURIk/AFapUiUNHjxYH3/8sb777jv17t1bc+bM0U033aS77767NGoEAAAACvS7vs62fv36euKJJzRhwgRVrlxZa9asuVZ1AQAAAFf1m77OVpI++eQTLVy4UG+++aY8PDzUp08fDR069FrWBgAAABSpRGH2p59+UkpKilJSUrR37161adNGs2bNUp8+fVSpUqXSqhEAAAAoULHDbNeuXbVx40b5+/srPj5eQ4YMUcOGDUuzNgAAAKBIxQ6z5cuX1xtvvKG77rpLnp6epVkTAAAAUCzFDrOrV68uzToAAACAEvtdqxkAAAAA7kSYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFjXRZidM2eOQkJC5O3trdatW2vLli3FGrds2TLZbDb16NGjdAsEAADAdcntYXb58uVKSEhQUlKStm/frubNmysmJkbHjx8vctyBAwf02GOPqV27dmVUKQAAAK43bg+zM2fO1PDhwzV48GA1adJEc+fOVcWKFbVw4cJCx+Tl5WnAgAGaMmWK6tatW4bVAgAA4Hri1jCbm5urbdu2KTo62tnm4eGh6Ohobd68udBxf//731WjRg0NHTr0qsfIyclRZmamywMAAAA3BreG2ZMnTyovL0+BgYEu7YGBgTp27FiBYz777DMtWLBA8+fPL9Yxpk2bJj8/P+cjODj4d9cNAACA64PbbzMoiaysLN1///2aP3++/P39izVm/PjxysjIcD4OHz5cylUCAACgrJRz58H9/f3l6emp9PR0l/b09HQFBQXl679v3z4dOHBAsbGxzjaHwyFJKleunPbs2aN69eq5jLHb7bLb7aVQPQAAANzNrTOzXl5eCg8PV2pqqrPN4XAoNTVVkZGR+fo3atRI//3vf5WWluZ83H333erYsaPS0tK4hQAAAOAPxq0zs5KUkJCgQYMGKSIiQq1atVJycrKys7M1ePBgSVJ8fLxq166tadOmydvbW02bNnUZX6VKFUnK1w4AAIAbn9vDbN++fXXixAlNmjRJx44dU1hYmNatW+f8UNihQ4fk4WHUrb0AAAAoIzbLsix3F1GWMjMz5efnp4yMDPn6+pbJMW22MjkMADf7Y11NXdmmcKEDbnRWUtld5EqS15jyBAAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsa6LMDtnzhyFhITI29tbrVu31pYtWwrtO3/+fLVr105Vq1ZV1apVFR0dXWR/AAAA3LjcHmaXL1+uhIQEJSUlafv27WrevLliYmJ0/PjxAvt/9NFHiouL04cffqjNmzcrODhYd955p3788ccyrhwAAADuZrMsy3JnAa1bt1bLli01e/ZsSZLD4VBwcLBGjRqlcePGXXV8Xl6eqlatqtmzZys+Pv6q/TMzM+Xn56eMjAz5+vr+7vqLw2Yrk8MAcDP3Xk3dyzaFCx1wo7OSyu4iV5K85taZ2dzcXG3btk3R0dHONg8PD0VHR2vz5s3F2sf58+d18eJFVatWrcDnc3JylJmZ6fIAAADAjcGtYfbkyZPKy8tTYGCgS3tgYKCOHTtWrH0kJiaqVq1aLoH416ZNmyY/Pz/nIzg4+HfXDQAAgOuD2++Z/T2mT5+uZcuWadWqVfL29i6wz/jx45WRkeF8HD58uIyrBAAAQGkp586D+/v7y9PTU+np6S7t6enpCgoKKnLs888/r+nTp2vjxo1q1qxZof3sdrvsdvs1qRcAAADXF7fOzHp5eSk8PFypqanONofDodTUVEVGRhY67tlnn9VTTz2ldevWKSIioixKBQAAwHXIrTOzkpSQkKBBgwYpIiJCrVq1UnJysrKzszV48GBJUnx8vGrXrq1p06ZJkp555hlNmjRJS5YsUUhIiPPeWh8fH/n4+LjtPAAAAFD23B5m+/btqxMnTmjSpEk6duyYwsLCtG7dOueHwg4dOiQPj/+bQH7llVeUm5urXr16uewnKSlJkydPLsvSAQAA4GZuX2e2rLHOLIDS8se6mrpinVngxsc6swAAAMA1RpgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxCLMAAAAwFmEWAAAAxiLMAgAAwFiEWQAAABiLMAsAAABjEWYBAABgLMIsAAAAjEWYBQAAgLEIswAAADAWYRYAAADGIswCAADAWIRZAAAAGIswCwAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAYxFmAQAAYCzCLAAAAIxFmAUAAICxroswO2fOHIWEhMjb21utW7fWli1biuy/YsUKNWrUSN7e3goNDdXatWvLqFIAAABcT9weZpcvX66EhAQlJSVp+/btat68uWJiYnT8+PEC+2/atElxcXEaOnSoduzYoR49eqhHjx765ptvyrhyAAAAuJvNsizLnQW0bt1aLVu21OzZsyVJDodDwcHBGjVqlMaNG5evf9++fZWdna13333X2Xb77bcrLCxMc+fOverxMjMz5efnp4yMDPn6+l67EymCzVYmhwHgZu69mrqXbQoXOuBGZyWV3UWuJHmtXBnVVKDc3Fxt27ZN48ePd7Z5eHgoOjpamzdvLnDM5s2blZCQ4NIWExOjt956q8D+OTk5ysnJcW5nZGRI+uVFAoBr6Q99Wbng7gIAlLayzE6Xj1WcOVe3htmTJ08qLy9PgYGBLu2BgYHavXt3gWOOHTtWYP9jx44V2H/atGmaMmVKvvbg4ODfWDUAFMzPz90VAEDp8Zte9he5rKws+V3l4urWMFsWxo8f7zKT63A4dPr0aVWvXl023v9HKcnMzFRwcLAOHz5cZrezAEBZ4RqH0mZZlrKyslSrVq2r9nVrmPX395enp6fS09Nd2tPT0xUUFFTgmKCgoBL1t9vtstvtLm1VqlT57UUDJeDr68uFHsANi2scStPVZmQvc+tqBl5eXgoPD1dqaqqzzeFwKDU1VZGRkQWOiYyMdOkvSRs2bCi0PwAAAG5cbr/NICEhQYMGDVJERIRatWql5ORkZWdna/DgwZKk+Ph41a5dW9OmTZMkjRkzRlFRUZoxY4a6d++uZcuWaevWrZo3b547TwMAAABu4PYw27dvX504cUKTJk3SsWPHFBYWpnXr1jk/5HXo0CF5ePzfBHKbNm20ZMkSTZgwQU888YQaNGigt956S02bNnXXKQD52O12JSUl5bvFBQBuBFzjcD1x+zqzAAAAwG/l9m8AAwAAAH4rwiwAAACMRZgFAACAsQizMFZISIiSk5OL3f+jjz6SzWbT2bNnS60mAABQtgizKHU2m63Ix+TJk3/Tfr/66is9+OCDxe7fpk0bHT16tNiLMF8LjRo1kt1uL/TrlgH8cZXWtfHyvt96661i93/ooYfk6empFStW/OZjAu5CmEWpO3r0qPORnJwsX19fl7bHHnvM2deyLF26dKlY+w0ICFDFihWLXYeXl5eCgoLK7GuMP/vsM/3888/q1auX/vnPf5bJMYty8eJFd5cA4FdKcm0sTefPn9eyZcv0+OOPa+HChWVyzKLk5ua6uwQYhjCLUhcUFOR8+Pn5yWazObd3796typUr67333lN4eLjsdrs+++wz7du3T/fcc48CAwPl4+Ojli1bauPGjS77vfI2A5vNptdee009e/ZUxYoV1aBBA61evdr5/JW3GaSkpKhKlSp6//331bhxY/n4+KhLly46evSoc8ylS5c0evRoValSRdWrV1diYqIGDRqkHj16XPW8FyxYoP79++v+++8v8B+II0eOKC4uTtWqVVOlSpUUERGhL7/80vn8O++8o5YtW8rb21v+/v7q2bOny7leOetSpUoVpaSkSJIOHDggm82m5cuXKyoqSt7e3lq8eLFOnTqluLg41a5dWxUrVlRoaKiWLl3qsh+Hw6Fnn31W9evXl91u10033aSnn35aktSpUyeNHDnSpf+JEyfk5eWV75v5ABStqGtjUFCQli1bpsaNG8vb21uNGjXSyy+/7Bybm5urkSNHqmbNmvL29ladOnWcXy4UEhIiSerZs6dsNptzuzArVqxQkyZNNG7cOH3yySc6fPiwy/M5OTlKTExUcHCw7Ha76tevrwULFjif//bbb3XXXXfJ19dXlStXVrt27bRv3z5JUocOHfToo4+67K9Hjx564IEHnNshISF66qmnFB8fL19fX+c7bomJibrllltUsWJF1a1bVxMnTsz3S3lh18m///3vBa4/HxYWpokTJxb5esA8hFlcF8aNG6fp06dr165datasmc6dO6du3bopNTVVO3bsUJcuXRQbG6tDhw4VuZ8pU6aoT58++vrrr9WtWzcNGDBAp0+fLrT/+fPn9fzzz+vf//63PvnkEx06dMhlNuSZZ57R4sWLtWjRIn3++efKzMws1lt3WVlZWrFihQYOHKg///nPysjI0Keffup8/ty5c4qKitKPP/6o1atXa+fOnXr88cflcDgkSWvWrFHPnj3VrVs37dixQ6mpqWrVqtVVj3ulcePGacyYMdq1a5diYmJ04cIFhYeHa82aNfrmm2/04IMP6v7779eWLVucY8aPH6/p06dr4sSJ+t///qclS5Y4v8Rk2LBhWrJkiXJycpz9//Of/6h27drq1KlTiesDULDFixdr0qRJevrpp7Vr1y5NnTpVEydOdL7LM2vWLK1evVqvv/669uzZo8WLFztD61dffSVJWrRokY4ePercLsyCBQs0cOBA+fn5qWvXrs5fii+Lj4/X0qVLNWvWLO3atUuvvvqqfHx8JEk//vij2rdvL7vdrg8++EDbtm3TkCFDiv0O22XPP/+8mjdvrh07djjDZuXKlZWSkqL//e9/evHFFzV//ny98MILzjFFXSeHDBmiXbt2uZz7jh079PXXXzu/YRQ3EAsoQ4sWLbL8/Pyc2x9++KElyXrrrbeuOvbWW2+1XnrpJed2nTp1rBdeeMG5LcmaMGGCc/vcuXOWJOu9995zOdaZM2ectUiy9u7d6xwzZ84cKzAw0LkdGBhoPffcc87tS5cuWTfddJN1zz33FFnrvHnzrLCwMOf2mDFjrEGDBjm3X331Vaty5crWqVOnChwfGRlpDRgwoND9S7JWrVrl0ubn52ctWrTIsizL+uGHHyxJVnJycpF1WpZlde/e3frrX/9qWZZlZWZmWna73Zo/f36BfX/++WeratWq1vLly51tzZo1syZPnnzV4wAo3JXXxnr16llLlixx6fPUU09ZkZGRlmVZ1qhRo6xOnTpZDoejwP0VdI0oyHfffWeVL1/eOnHihGVZlrVq1Srr5ptvdu53z549liRrw4YNBY4fP368dfPNN1u5ubkFPh8VFWWNGTPGpe2ee+5xuR7WqVPH6tGjx1Vrfe6556zw8HDn9tWuk127drUefvhh5/aoUaOsDh06XPU4MA8zs7guREREuGyfO3dOjz32mBo3bqwqVarIx8dHu3btuurMbLNmzZx/rlSpknx9fXX8+PFC+1esWFH16tVzbtesWdPZPyMjQ+np6S4zop6engoPD7/q+SxcuFADBw50bg8cOFArVqxQVlaWJCktLU0tWrRQtWrVChyflpamzp07X/U4V3Pl65qXl6ennnpKoaGhqlatmnx8fPT+++87X9ddu3YpJyen0GN7e3u73Daxfft2ffPNNy5vGQL4fbKzs7Vv3z4NHTpUPj4+zsc//vEP59v3DzzwgNLS0tSwYUONHj1a69ev/03HWrhwoWJiYuTv7y9J6tatmzIyMvTBBx9I+uVa5OnpqaioqALHp6WlqV27dipfvvxvOv5lV16rJGn58uVq27atgoKC5OPjowkTJrj8G3C16+Tw4cO1dOlSXbhwQbm5uVqyZImGDBnyu+rE9amcuwsApF+C56899thj2rBhg55//nnVr19fFSpUUK9eva76wYArL6g2m8351n1x+1u/8xue//e//+mLL77Qli1blJiY6GzPy8vTsmXLNHz4cFWoUKHIfVzt+YLqLOgDXle+rs8995xefPFFJScnKzQ0VJUqVdKjjz7qfF2vdlzpl1sNwsLCdOTIES1atEidOnVSnTp1rjoOQPGcO3dOkjR//ny1bt3a5TlPT09J0m233aYffvhB7733njZu3Kg+ffooOjpab7zxRrGPk5eXp3/+8586duyYypUr59K+cOFCde7c+Xdfqzw8PH7TtWrz5s0aMGCApkyZopiYGPn5+WnZsmWaMWNGsY8dGxsru92uVatWycvLSxcvXlSvXr2KHAMzMTOL69Lnn3+uBx54QD179lRoaKiCgoJ04MCBMq3Bz89PgYGBLvdc5eXlafv27UWOW7Bggdq3b6+dO3cqLS3N+UhISHB+aKJZs2ZKS0sr9H7eZs2aFfmBqoCAAJcPqn3//fc6f/78Vc/p888/1z333KOBAweqefPmqlu3rr777jvn8w0aNFCFChWKPHZoaKgiIiI0f/58ZjqAUhAYGKhatWpp//79ql+/vsvj5ptvdvbz9fVV3759NX/+fC1fvlxvvvmm85pSvnx55eXlFXmctWvXKisrSzt27HC5Vi1dulQrV67U2bNnFRoaKofDoY8//rjAfTRr1kyffvppoaulXHmtysvL0zfffHPV12DTpk2qU6eOnnzySUVERKhBgwY6ePBgvmMXda0qV66cBg0apEWLFmnRokXq169fsX5hh3mYmcV1qUGDBlq5cqViY2Nls9k0ceLEImdYS8uoUaM0bdo01a9fX40aNdJLL72kM2fOFLq818WLF/Xvf/+7wE/SDhs2TDNnztS3336ruLg4TZ06VT169NC0adNUs2ZN7dixQ7Vq1VJkZKSSkpLUuXNn1atXT/369dOlS5e0du1a50xvp06dNHv2bEVGRiovL0+JiYnFepuvQYMGeuONN7Rp0yZVrVpVM2fOVHp6upo0aSLpl9sIEhMT9fjjj8vLy0tt27bViRMn9O2332ro0KEu5zJy5EhVqlTJZZUFANfGlClTNHr0aPn5+alLly7KycnR1q1bdebMGSUkJGjmzJmqWbOmWrRoIQ8PD61YsUJBQUGqUqWKpF9WCEhNTVXbtm1lt9tVtWrVfMdYsGCBunfvrubNm7u0N2nSRGPHjtXixYv1yCOPaNCgQRoyZIhmzZql5s2b6+DBgzp+/Lj69OmjkSNH6qWXXlK/fv00fvx4+fn56YsvvlCrVq3UsGFDderUSQkJCVqzZo3q1aunmTNnFuuLaxo0aKBDhw5p2bJlatmypdasWaNVq1a59LnadVL65VrVuHFjSb/8Mo8bEzOzuC7NnDlTVatWVZs2bRQbG6uYmBjddtttZV5HYmKi4uLiFB8fr8jISPn4+CgmJkbe3t4F9l+9erVOnTpVYMBr3LixGjdurAULFsjLy0vr169XjRo11K1bN4WGhmr69OnOtxA7dOigFStWaPXq1QoLC1OnTp1cVhyYMWOGgoOD1a5dO/Xv31+PPfZYsdbcnTBhgm677TbFxMSoQ4cOCgoKyrfM2MSJE/XXv/5VkyZNUuPGjdW3b9989x3HxcWpXLlyiouLK/S1APDbDRs2TK+99poWLVqk0NBQRUVFKSUlxTkzW7lyZT377LOKiIhQy5YtdeDAAa1du1YeHr/8sz5jxgxt2LBBwcHBatGiRb79p6ena82aNbrvvvvyPefh4aGePXs630l65ZVX1KtXL40YMUKNGjXS8OHDlZ2dLUmqXr26PvjgA+cKLeHh4Zo/f77zl+shQ4Zo0KBBio+PV1RUlOrWrauOHTte9fzvvvtujR07ViNHjlRYWJg2bdqUb0mtq10npV9CcZs2bdSoUaN8t2zgxmGzfu8NgsAfiMPhUOPGjdWnTx899dRT7i7HbQ4cOKB69erpq6++cssvGQBQHJZlqUGDBhoxYoQSEhLcXQ5KCbcZAEU4ePCg1q9fr6ioKOXk5Gj27Nn64Ycf1L9/f3eX5hYXL17UqVOnNGHCBN1+++0EWQDXrRMnTmjZsmU6duwYa8ve4AizQBE8PDyUkpKixx57TJZlqWnTptq4caPzHqw/ms8//1wdO3bULbfcUqJPTQNAWatRo4b8/f01b968Au8Zxo2D2wwAAABgLD4ABgAAAGMRZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAJAKdi8ebM8PT3VvXt3d5cCADc01pkFgFIwbNgw+fj4aMGCBdqzZ49q1arlljpyc3Pl5eXllmMDQFlgZhYArrFz585p+fLlevjhh9W9e3elpKS4PP/OO++oZcuW8vb2lr+/v3r27Ol8LicnR4mJiQoODpbdblf9+vW1YMECSVJKSoqqVKnisq+33npLNpvNuT158mSFhYXptdde08033yxvb29J0rp163THHXeoSpUqql69uu666y7t27fPZV9HjhxRXFycqlWrpkqVKikiIkJffvmlDhw4IA8PD23dutWlf3JysurUqSOHw/F7XzIA+M0IswBwjb3++utq1KiRGjZsqIEDB2rhwoW6/CbYmjVr1LNnT3Xr1k07duxQamqqWrVq5RwbHx+vpUuXatasWdq1a5deffVV+fj4lOj4e/fu1ZtvvqmVK1cqLS1NkpSdna2EhARt3bpVqamp8vDwUM+ePZ1B9Ny5c4qKitKPP/6o1atXa+fOnXr88cflcDgUEhKi6OhoLVq0yOU4ixYt0gMPPCAPD/4pAeBGFgDgmmrTpo2VnJxsWZZlXbx40fL397c+/PBDy7IsKzIy0howYECB4/bs2WNJsjZs2FDg84sWLbL8/Pxc2latWmX9+lKelJRklS9f3jp+/HiRNZ44ccKSZP33v/+1LMuyXn31Vaty5crWqVOnCuy/fPlyq2rVqtaFCxcsy7Ksbdu2WTabzfrhhx+KPA4AlDZ+nQaAa2jPnj3asmWL4uLiJEnlypVT3759nbcKpKWlqXPnzgWOTUtLk6enp6Kion5XDXXq1FFAQIBL2/fff6+4uDjVrVtXvr6+CgkJkSQdOnTIeewWLVqoWrVqBe6zR48e8vT01KpVqyT9cstDx44dnfsBAHcp5+4CAOBGsmDBAl26dMnlA1+WZclut2v27NmqUKFCoWOLek6SPDw8nLcrXHbx4sV8/SpVqpSvLTY2VnXq1NH8+fNVq1YtORwONW3aVLm5ucU6tpeXl+Lj47Vo0SLde++9WrJkiV588cUixwBAWWBmFgCukUuXLulf//qXZsyYobS0NOdj586dqlWrlpYuXapmzZopNTW1wPGhoaFyOBz6+OOPC3w+ICBAWVlZys7OdrZdvie2KKdOndKePXs0YcIEde7cWY0bN9aZM2dc+jRr1kxpaWk6ffp0ofsZNmyYNm7cqJdfflmXLl3Svffee9VjA0BpY2YWAK6Rd999V2fOnNHQoUPl5+fn8tx9992nBQsW6LnnnlPnzp1Vr1499evXT5cuXdLatWuVmJiokJAQDRo0SEOGDNGsWbPUvHlzHTx4UMePH1efPn3UunVrVaxYUU888YRGjx6tL7/8Mt9KCQWpWrWqqlevrnnz5qlmzZo6dOiQxo0b59InLi5OU6dOVY8ePTRt2jTVrFlTO3bsUK1atRQZGSlJaty4sW6//XYlJiZqyJAhV53NBYCywMwsAFwjCxYsUHR0dL4gK/0SZrdu3apq1appxYoVWr16tcLCwtSpUydt2bLF2e+VV15Rr169NGLECDVq1EjDhw93zsRWq1ZN//nPf7R27VqFhoZq6dKlmjx58lXr8vDw0LJly7Rt2zY1bdpUY8eO1XPPPefSx8vLS+vXr1eNGjXUrVs3hYaGavr06fL09HTpN3ToUOXm5mrIkCG/4RUCgGuPL00AABTbU089pRUrVujrr792dykAIImZWQBAMZw7d07ffPONZs+erVGjRrm7HABwIswCAK5q5MiRCg8PV4cOHbjFAMB1hdsMAAAAYCxmZgEAAGAswiwAAACMRZgFAACAsQizAAAAMBZhFgAAAMYizAIAAMBYhFkAAAAYizALAAAAY/0/r8py+UGJbXcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.6\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Calculate training accuracy\n",
        "    train_accuracy = model.score(X_train_scaled, y_train)\n",
        "\n",
        "    # Calculate test accuracy\n",
        "    test_accuracy = model.score(X_test_scaled, y_test)\n",
        "\n",
        "    print(\"Training Accuracy:\", train_accuracy)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "    # Visualize accuracy\n",
        "    labels = ['Training Accuracy', 'Test Accuracy']\n",
        "    accuracies = [train_accuracy, test_accuracy]\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.bar(labels, accuracies, color=['blue', 'green'])\n",
        "    plt.xlabel('Accuracy')\n",
        "    plt.ylabel('Value')\n",
        "    plt.title('Model Accuracy Comparison')\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # 2. Feature Extraction\n",
        "    X_features = extract_features(X)\n",
        "\n",
        "    # 3. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X_features, y)\n",
        "\n",
        "    # 4. Model Training\n",
        "    model = train_model(X_train, y_train)\n",
        "\n",
        "    # 5. Model Evaluation\n",
        "    train_accuracy, test_accuracy = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
        "    print(\"Training Accuracy:\", train_accuracy)\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "wHS2fWHwdEhd",
        "outputId": "deefdb19-f582-4b71-b90c-49adcafa6565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 6s 1s/step - loss: 6.1139 - accuracy: 0.4500 - val_loss: 1.1147 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 4s 1s/step - loss: 2.1646 - accuracy: 0.4500 - val_loss: 1.2125 - val_accuracy: 0.3000\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 11s 4s/step - loss: 0.7706 - accuracy: 0.6000 - val_loss: 0.6460 - val_accuracy: 0.7000\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 6s 1s/step - loss: 0.9510 - accuracy: 0.4500 - val_loss: 0.7038 - val_accuracy: 0.3000\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.7348 - accuracy: 0.5500 - val_loss: 0.8359 - val_accuracy: 0.3000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 6s 1s/step - loss: 0.7122 - accuracy: 0.5500 - val_loss: 0.7096 - val_accuracy: 0.3000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6901 - accuracy: 0.5500 - val_loss: 0.7016 - val_accuracy: 0.3000\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6897 - accuracy: 0.5500 - val_loss: 0.7042 - val_accuracy: 0.3000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 5s 2s/step - loss: 0.6893 - accuracy: 0.5500 - val_loss: 0.7018 - val_accuracy: 0.3000\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 4s 1s/step - loss: 0.6885 - accuracy: 0.5500 - val_loss: 0.6958 - val_accuracy: 0.3000\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'Sequential' object has no attribute 'predict_classes'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2e1e971a1140>\u001b[0m in \u001b[0;36m<cell line: 90>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-2e1e971a1140>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# 5. Model Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2e1e971a1140>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_test, y_test)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# 5. Model Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'predict_classes'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the path to your dataset directory\n",
        "dataset_path = \"/content/drive/MyDrive/dataset/hw_drawings/hw_drawings\"\n",
        "\n",
        "# 1. Load and Preprocess the Dataset\n",
        "def load_dataset(dataset_path):\n",
        "    X = []  # List to hold images\n",
        "    y = []  # List to hold corresponding labels\n",
        "\n",
        "    label_mapping = {}  # Dictionary to map folder names to numeric labels\n",
        "    current_label = 0\n",
        "\n",
        "    for folder_name in os.listdir(dataset_path):\n",
        "        folder_path = os.path.join(dataset_path, folder_name)\n",
        "        if os.path.isdir(folder_path):\n",
        "            label_mapping[folder_name] = current_label\n",
        "            current_label += 1\n",
        "            label = label_mapping[folder_name]\n",
        "            for filename in os.listdir(folder_path):\n",
        "                file_path = os.path.join(folder_path, filename)\n",
        "                if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "                    # Load and preprocess image\n",
        "                    img = cv2.imread(file_path)\n",
        "                    img = cv2.resize(img, (224, 224))  # Resize to match CNN input size\n",
        "                    img = img / 255.0  # Normalize pixel values to [0, 1]\n",
        "                    X.append(img)\n",
        "                    y.append(label)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# 2. Splitting the Dataset\n",
        "def split_dataset(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# 3. Define the CNN Model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# 4. Model Training\n",
        "def train_model(X_train, y_train, X_test, y_test, num_classes):\n",
        "    input_shape = X_train.shape[1:]  # Shape of input images\n",
        "    model = create_cnn_model(input_shape, num_classes)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "    return model\n",
        "\n",
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict_classes(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Test Accuracy:\", accuracy)\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # 2. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
        "\n",
        "    # 3. Model Training\n",
        "    num_classes = len(np.unique(y))\n",
        "    model = train_model(X_train, y_train, X_test, y_test, num_classes)\n",
        "\n",
        "    # 5. Model Evaluation\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxPLtc-Vdiw3"
      },
      "outputs": [],
      "source": [
        "# 5. Model Evaluation\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Test Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "KFJoautPdrhr",
        "outputId": "3b2bb343-14ff-4e30-cb53-689a866cf147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'num_classes' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-438798123c69>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# 1. Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# 2. Transfer Learning with Pre-trained Model\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = Flatten()(base_model.output)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model using data augmentation\n",
        "history = model.fit(train_datagen.flow(X_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(X_train) / 32, epochs=10,\n",
        "                    validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "evaluate_model(model, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "R4yLgAgLdx-Q",
        "outputId": "eeacade6-46d7-430f-9d06-de2f3db6060a"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'y' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e6d7f0330c08>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the number of classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Continue with the rest of the code for data augmentation and transfer learning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ],
      "source": [
        "# Define the number of classes\n",
        "num_classes = len(np.unique(y))\n",
        "\n",
        "# Continue with the rest of the code for data augmentation and transfer learning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JgnZ7dwd47p",
        "outputId": "5e3f229a-ca2c-4fee-b4e6-ad41c38bc944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 37s 62s/step - loss: 1.5146 - accuracy: 0.6000 - val_loss: 7.3914 - val_accuracy: 0.3000\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 36s 107s/step - loss: 2.3094 - accuracy: 0.6000 - val_loss: 1.7124 - val_accuracy: 0.7000\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 35s 59s/step - loss: 2.6985 - accuracy: 0.5500 - val_loss: 6.7397 - val_accuracy: 0.3000\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 35s 58s/step - loss: 5.1529 - accuracy: 0.5500 - val_loss: 0.9920 - val_accuracy: 0.7000\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 37s 126s/step - loss: 3.3481 - accuracy: 0.5250 - val_loss: 3.8642 - val_accuracy: 0.7000\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 33s 112s/step - loss: 1.8037 - accuracy: 0.5000 - val_loss: 1.7327 - val_accuracy: 0.3000\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 35s 60s/step - loss: 3.1125 - accuracy: 0.5750 - val_loss: 0.8965 - val_accuracy: 0.6000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 37s 65s/step - loss: 2.1374 - accuracy: 0.5750 - val_loss: 2.2580 - val_accuracy: 0.7000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 35s 60s/step - loss: 1.8346 - accuracy: 0.5500 - val_loss: 1.2585 - val_accuracy: 0.4000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 36s 120s/step - loss: 1.8492 - accuracy: 0.6750 - val_loss: 1.6701 - val_accuracy: 0.4000\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "Test Accuracy: 0.4\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    # 1. Load and Preprocess the Dataset\n",
        "    X, y = load_dataset(dataset_path)\n",
        "\n",
        "    # Define the number of classes\n",
        "    num_classes = len(np.unique(y))\n",
        "\n",
        "    # 2. Splitting the Dataset\n",
        "    X_train, X_test, y_train, y_test = split_dataset(X, y)\n",
        "\n",
        "    # 3. Data Augmentation\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    # 4. Transfer Learning with Pre-trained Model\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    x = Flatten()(base_model.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model using data augmentation\n",
        "    history = model.fit(train_datagen.flow(X_train, y_train, batch_size=32),\n",
        "                        steps_per_epoch=len(X_train) / 32, epochs=10,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(model, X_test, y_test)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1BpKzCfolj8EmKV87Avi3irxuBnoiFZ0v",
      "authorship_tag": "ABX9TyOPXWNYo9BtKQGXq8ftKOEf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}